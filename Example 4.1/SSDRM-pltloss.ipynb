{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f89ad74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "import time\n",
    "from pyDOE import lhs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker\n",
    "import math\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': print(torch.cuda.get_device_name()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c84154d",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "\n",
    "Training and Testing data is prepared from the solution file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "94c9ce7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = np.linspace(-1,1,256)\n",
    "x_2 = np.linspace(1,-1,256)\n",
    "\n",
    "X, Y = np.meshgrid(x_1,x_2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584d4f6e",
   "metadata": {},
   "source": [
    "# Test Data\n",
    "\n",
    "We prepare the test data to compare against the solution produced by the DRM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "99560bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_v_test = np.hstack((X.flatten(order='F')[:,None], Y.flatten(order='F')[:,None]))\n",
    "\n",
    "lb = np.array([-1, -1]) #lower bound\n",
    "ub = np.array([1, 1])  #upper bound\n",
    "\n",
    "usol = -1/(2 * np.pi) * np.log(X**2 + Y**2) + math.e**(X*Y)*np.cos(X)\n",
    "vsol = math.e**(X*Y)*np.cos(X)\n",
    "\n",
    "v_true = vsol.flatten('F')[:,None] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d05d479",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a7a92c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingdata(N_v,N_f):\n",
    "    \n",
    "    leftedge_x = np.hstack((X[:,0][:,None], Y[:,0][:,None]))\n",
    "    leftedge_v = vsol[:,0][:,None]\n",
    "    \n",
    "    rightedge_x = np.hstack((X[:,-1][:,None], Y[:,-1][:,None]))\n",
    "    rightedge_v = vsol[:,-1][:,None]\n",
    "    \n",
    "    topedge_x = np.hstack((X[0,:][:,None], Y[0,:][:,None]))\n",
    "    topedge_v = vsol[0,:][:,None]\n",
    "    \n",
    "    bottomedge_x = np.hstack((X[-1,:][:,None], Y[-1,:][:,None]))\n",
    "    bottomedge_v = vsol[-1,:][:,None]\n",
    "    \n",
    "    all_X_v_train = np.vstack([leftedge_x, rightedge_x, bottomedge_x, topedge_x])\n",
    "    all_v_train = np.vstack([leftedge_v, rightedge_v, bottomedge_v, topedge_v])  \n",
    "     \n",
    "    #choose random N_v points for training\n",
    "    idx = np.random.choice(all_X_v_train.shape[0], N_v, replace=False) \n",
    "    \n",
    "    X_v_train = all_X_v_train[idx[0:N_v], :] #choose indices from  set 'idx' (x,t)\n",
    "    v_train = all_v_train[idx[0:N_v],:]      #choose corresponding v\n",
    "    \n",
    "    '''Collocation Points'''\n",
    "\n",
    "    # N_f sets of tuples(x,t)\n",
    "    X_f = lb + (ub-lb)*lhs(2,N_f)\n",
    "    X_f_train = np.vstack((X_f, X_v_train)) # append training points to collocation points \n",
    "    \n",
    "    return X_f_train, X_v_train, v_train "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edf6b7f",
   "metadata": {},
   "source": [
    "# SSDRM\n",
    "\n",
    "Creating sequential layers using the class\n",
    "tf.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f82fa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "        'activation function'\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        'loss function'\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "    \n",
    "        'Initialise neural network as a nn.MSELosslist using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "    \n",
    "        'Xavier Normal Initialization'\n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        for i in range(len(layers)-1):\n",
    "            \n",
    "            # weights from a normal distribution with \n",
    "            # Recommended gain value for tanh = 5/3?\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            \n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "            \n",
    "\n",
    "    def forward(self,x):\n",
    "        \n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "                      \n",
    "        #preprocessing input \n",
    "        x = (x - l_b)/(u_b - l_b) #feature scaling\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            \n",
    "            z = self.linears[i](a)\n",
    "                        \n",
    "            a = self.activation(z)\n",
    "            \n",
    "        a = self.linears[-1](a)\n",
    "        \n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,x,y):\n",
    "                \n",
    "        loss_v = self.loss_function(self.forward(x), y)\n",
    "                \n",
    "        return loss_v\n",
    "    \n",
    "    def loss_PDE(self, x_to_train_f):\n",
    "                \n",
    "        x_1_f = x_to_train_f[:,[0]]\n",
    "        x_2_f = x_to_train_f[:,[1]]\n",
    "                        \n",
    "        g = x_to_train_f.clone()\n",
    "                        \n",
    "        g.requires_grad = True\n",
    "        \n",
    "        v = self.forward(g)\n",
    "                \n",
    "        v_x = autograd.grad(v,g,torch.ones([x_to_train_f.shape[0], 1]).to(device), retain_graph=True, create_graph=True)[0]\n",
    "                                                            \n",
    "        v_x_1 = v_x[:,[0]]\n",
    "        \n",
    "        v_x_2 = v_x[:,[1]]\n",
    "                        \n",
    "        k = x_1_f**2 + x_2_f**2 + 1\n",
    "        F = (x_1_f**2+x_2_f**2+1)*((1-x_1_f**2-x_2_f**2)*math.e**(x_1_f*x_2_f)*np.cos(x_1_f)+2*x_2_f*math.e**(x_1_f*x_2_f)*np.sin(x_1_f))-4*x_1_f*x_2_f*math.e**(x_1_f*x_2_f)*np.cos(x_1_f)+2*x_1_f*math.e**(x_1_f*x_2_f)*np.sin(x_1_f)\n",
    "        \n",
    "        f = 1/2 * k * (v_x_1**2 + v_x_2**2) - F * v\n",
    "\n",
    "        loss_f = torch.mean(f)\n",
    "                \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self,x,y,x_to_train_f,sigma):\n",
    "\n",
    "        loss_v = self.loss_BC(x,y)\n",
    "        loss_f = self.loss_PDE(x_to_train_f)\n",
    "\n",
    "        loss = sigma/2 * loss_v + loss_f\n",
    "\n",
    "        return loss\n",
    "     \n",
    "    'callable for optimizer'                                       \n",
    "    def closure(self):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss_val = self.loss(X_v_train, v_train, X_f_train, sigma)\n",
    "        \n",
    "        error_vec, _ = SSDRM.test()\n",
    "        \n",
    "        global ite, iteration_vec, fun_vec\n",
    "        ite = ite + 1\n",
    "        \n",
    "        if (ite % 100 == 0):\n",
    "            iteration_vec.append(ite)\n",
    "            fun_vec.append(loss_val.item())\n",
    "\n",
    "        loss_val.backward()\n",
    "        \n",
    "        return loss_val        \n",
    "    \n",
    "    def test(self):\n",
    "                \n",
    "        v_pred = self.forward(X_v_test_tensor)\n",
    "        \n",
    "        error_vec = torch.linalg.norm((v-v_pred),2)/torch.linalg.norm(v,2)        # Relative L2 Norm of the error (Vector)\n",
    "        \n",
    "        v_pred = np.reshape(v_pred.cpu().detach().numpy(),(256,256),order='F') \n",
    "        \n",
    "        return error_vec, v_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea9853d",
   "metadata": {},
   "source": [
    "# Loss Function\n",
    "\n",
    "The loss function consists of two parts:\n",
    "\n",
    "    loss_BC: MSE error of boundary losses\n",
    "    loss_PDE: variational functional for the PDE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d71f69f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentialmodel(\n",
      "  (activation): Tanh()\n",
      "  (loss_function): MSELoss()\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=20, bias=True)\n",
      "    (1): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (2): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (3): Linear(in_features=20, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Training time: 49.86\n",
      "sigma: 1153.300000\n",
      "Test Error: 0.01352\n",
      "[100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300] [-0.2808475196361542, -0.5662410855293274, -0.5792199373245239, -0.5915769934654236, -0.592842161655426, -0.5936079025268555, -0.5940036177635193, -0.5943702459335327, -0.5945678353309631, -0.5951025485992432, -0.5954800844192505, -0.5956221222877502, -0.5957692265510559]\n"
     ]
    }
   ],
   "source": [
    "N_v = 400 \n",
    "N_f = 10000 \n",
    "\n",
    "X_f_train_np_array, X_v_train_np_array, v_train_np_array = trainingdata(N_v,N_f)\n",
    "\n",
    "'Convert to tensor and send to GPU'\n",
    "X_f_train = torch.from_numpy(X_f_train_np_array).float().to(device)\n",
    "X_v_train = torch.from_numpy(X_v_train_np_array).float().to(device)\n",
    "v_train = torch.from_numpy(v_train_np_array).float().to(device)\n",
    "X_v_test_tensor = torch.from_numpy(X_v_test).float().to(device)\n",
    "v = torch.from_numpy(v_true).float().to(device)\n",
    "\n",
    "iteration_vec = []\n",
    "fun_vec = []\n",
    "\n",
    "layers = np.array([2, 20, 20, 20, 1])\n",
    "\n",
    "SSDRM = Sequentialmodel(layers)\n",
    "       \n",
    "SSDRM.to(device)\n",
    "\n",
    "'Neural Network Summary'\n",
    "\n",
    "print(SSDRM)\n",
    "params = list(SSDRM.parameters())\n",
    "\n",
    "sigma = 1153.3\n",
    "start_time = time.time()\n",
    "\n",
    "ite = 0\n",
    "optimizer = torch.optim.LBFGS(SSDRM.parameters(), lr=0.1, \n",
    "                              max_iter = 20000, \n",
    "                              max_eval = None, \n",
    "                              tolerance_grad = 1e-06, \n",
    "                              tolerance_change = 1e-09, \n",
    "                              history_size = 100, \n",
    "                              line_search_fn = 'strong_wolfe')\n",
    "\n",
    "optimizer.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "optimizer.step(SSDRM.closure)\n",
    "error_vec, _ = SSDRM.test()\n",
    " \n",
    "elapsed = time.time() - start_time                \n",
    "print('Training time: %.2f' % (elapsed))\n",
    "\n",
    "''' Model Accuracy ''' \n",
    "error_vec, v_pred = SSDRM.test()\n",
    "\n",
    "print('sigma: %f' %(sigma))\n",
    "print('Test Error: %.5f'  % (error_vec))\n",
    "\n",
    "print(iteration_vec,fun_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "173afd33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "import matplotlib.ticker\n",
    "\n",
    "iter_vec=[100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300] \n",
    "fun_vec=[-0.2808475196361542, -0.5662410855293274, -0.5792199373245239, -0.5915769934654236, -0.592842161655426, -0.5936079025268555, -0.5940036177635193, -0.5943702459335327, -0.5945678353309631, -0.5951025485992432, -0.5954800844192505, -0.5956221222877502, -0.5957692265510559]\n",
    "\n",
    "plt.figure(1, figsize=(6, 5))\n",
    "plt.xlabel('$i$',size=15)\n",
    "plt.ylabel('$L$',size=15)\n",
    "plt.tick_params(labelsize=12)\n",
    "x_major_locator=MultipleLocator(300)\n",
    "ax=plt.gca()\n",
    "ax.xaxis.set_major_locator(x_major_locator)\n",
    "y_major_locator=MultipleLocator(0.1)\n",
    "ax=plt.gca()\n",
    "ax.yaxis.set_major_locator(y_major_locator)\n",
    "plt.plot(iter_vec,fun_vec,color='c',marker='.',markersize=8)\n",
    "plt.grid(linestyle=\":\")\n",
    "plt.savefig('lossfunction',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1915e363",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
